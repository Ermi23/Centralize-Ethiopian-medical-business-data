{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Table Creation\n",
    "\n",
    "#### 1. Connect to PostgreSQL:\n",
    " Let's start by creating the connection to your PostgreSQL instance using SQLAlchemy and psycopg2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to the database!\n",
      "Tables created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Import the DBConnection class from scripts.db_connection\n",
    "import os\n",
    "os.chdir(r'c:\\users\\ermias.tadesse\\10x\\Centralize-Ethiopian-medical-business-data')  # Set the working directory to the project root\n",
    "from scripts.db_connection import DBConnection\n",
    "from sqlalchemy import MetaData, Table, Column, Integer, String, DateTime, ForeignKey\n",
    "import logging\n",
    "\n",
    "# Create a connection instance\n",
    "db = DBConnection(dbname='Central_Medical_Warehouse', user='postgres', password='Ermi@123')\n",
    "\n",
    "# Connect to the database\n",
    "db.connect()\n",
    "\n",
    "os.chdir(r'c:\\Users\\ermias.tadesse\\10x\\Centralize-Ethiopian-medical-business-data\\logs')\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(filename='Load_Data_To_Database.log', level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s:%(message)s')\n",
    "\n",
    "logging.info(f'Successfully connected to The Postgrass database: {db.dbname}')\n",
    "\n",
    "# Initialize metadata for creating tables\n",
    "metadata = MetaData()\n",
    "\n",
    "# Define your tables\n",
    "channels_table = Table('channels', metadata,\n",
    "    Column('channel_id', Integer, primary_key=True, autoincrement=True),\n",
    "    Column('channel_name', String, unique=True, nullable=False)\n",
    ")\n",
    "\n",
    "senders_table = Table('senders', metadata,\n",
    "    Column('sender_id', Integer, primary_key=True),\n",
    "    Column('sender_name', String)  # Optional if you want to track sender names\n",
    ")\n",
    "\n",
    "messages_table = Table('messages', metadata,\n",
    "    Column('message_id', Integer, primary_key=True),\n",
    "    Column('message', String, nullable=False),\n",
    "    Column('date', DateTime, nullable=False),\n",
    "    Column('sender_id', Integer, ForeignKey('senders.sender_id'), nullable=False),\n",
    "    Column('channel_id', Integer, ForeignKey('channels.channel_id'), nullable=False)\n",
    ")\n",
    "\n",
    "media_table = Table('media', metadata,\n",
    "    Column('media_id', Integer, primary_key=True, autoincrement=True),\n",
    "    Column('media_path', String, nullable=False),\n",
    "    Column('message_id', Integer, ForeignKey('messages.message_id'), nullable=False)\n",
    ")\n",
    "\n",
    "# Create the tables in the PostgreSQL database\n",
    "if db.engine:\n",
    "    metadata.create_all(db.engine)\n",
    "    print(\"Tables created successfully.\")\n",
    "    logging.info(f'Tables created successfully.')\n",
    "else:\n",
    "    print(\"Failed to create tables due to no connection.\")\n",
    "    logging.info(f'Failed to create tables due to no connection.')\n",
    "\n",
    "# # Close the connection after operations are done\n",
    "# db.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database Design \n",
    "Tables:\n",
    "Channels Table:\n",
    "\n",
    "channel_id: Primary Key, auto-incremented.\n",
    "channel_name: Unique name of the Telegram channel.\n",
    "Senders Table:\n",
    "\n",
    "sender_id: Primary Key.\n",
    "sender_name: (optional) - if the sender has an associated name or username.\n",
    "Messages Table:\n",
    "\n",
    "message_id: Primary Key.\n",
    "message: The text of the message.\n",
    "date: The date the message was posted.\n",
    "sender_id: Foreign Key from the Senders table.\n",
    "channel_id: Foreign Key from the Channels table.\n",
    "Media Table:\n",
    "\n",
    "media_id: Primary Key, auto-incremented.\n",
    "media_path: Path to the media file.\n",
    "message_id: Foreign Key from the Messages table.\n",
    "\n",
    "Explanation of Tables:\n",
    "channels: Stores unique channel names.\n",
    "senders: Stores unique senders based on sender_id.\n",
    "messages: Stores each message, linking it to a channel and sender.\n",
    "media: Stores the media paths related to messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert Data from scraped_data_cleaned.xlsx\n",
    "Next, we’ll load the cleaned Excel data, split it into the respective tables, and insert it into the PostgreSQL database.\n",
    "\n",
    "Load Excel Data and Prepare for Insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read the cleaned data from Excel.\n",
      "channels Data inserted successfully.\n",
      "senders Data inserted successfully.\n",
      "Data inserted successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "\n",
    "# Set up logging configuration\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Change to your working directory\n",
    "os.chdir(r'c:\\Users\\ermias.tadesse\\10x\\Centralize-Ethiopian-medical-business-data')\n",
    "\n",
    "# Load cleaned data from Excel\n",
    "scraped_data = pd.read_excel('data/cleaned/scraped_data_cleaned.xlsx')\n",
    "logging.info('Read the cleaned data from Excel')\n",
    "print(\"Read the cleaned data from Excel.\")\n",
    "# Create a session using the correct engine from DBConnection\n",
    "# Assuming 'db.engine' is defined somewhere in your code\n",
    "Session = sessionmaker(bind=db.engine)\n",
    "session = Session()\n",
    "logging.info('Created a session using the correct engine from DBConnection')\n",
    "\n",
    "# Insert channels (bulk insert)\n",
    "channels = [{'channel_name': channel} for channel in scraped_data['channel_name'].unique()]\n",
    "session.execute(channels_table.insert().values(channels))\n",
    "# Commit the session\n",
    "session.commit()\n",
    "logging.info('Bulk inserted channels')\n",
    "logging.info(\"Data inserted channels successfully.\")\n",
    "print(\"channels Data inserted successfully.\")\n",
    "# Insert senders (bulk insert, cast to int)\n",
    "senders = [{'sender_id': int(sender_id)} for sender_id in scraped_data['sender_id'].unique()]\n",
    "session.execute(senders_table.insert().values(senders))\n",
    "# Commit the session\n",
    "session.commit()\n",
    "logging.info('Bulk inserted senders')\n",
    "logging.info(\"Data inserted senders successfully.\")\n",
    "print(\"senders Data inserted successfully.\")\n",
    "# Prepare messages and media for bulk insert\n",
    "messages = []\n",
    "media_entries = []\n",
    "\n",
    "for index, row in scraped_data.iterrows():\n",
    "    # Get channel_id for this message\n",
    "    channel_id = session.execute(\n",
    "        channels_table.select().where(channels_table.c.channel_name == row['channel_name'])\n",
    "    ).fetchone()[0]\n",
    "    \n",
    "    # Prepare message entry\n",
    "    messages.append({\n",
    "        'message_id': int(row['message_id']),  # Cast to int\n",
    "        'message': row['message'],\n",
    "        'date': row['date'],\n",
    "        'sender_id': int(row['sender_id']),  # Cast to int\n",
    "        'channel_id': channel_id\n",
    "    })\n",
    "\n",
    "    # Prepare media entry if media path exists\n",
    "    if pd.notnull(row['media_path']):\n",
    "        media_entries.append({\n",
    "            'media_path': row['media_path'],\n",
    "            'message_id': int(row['message_id'])  # Cast to int\n",
    "        })\n",
    "\n",
    "# Proceed with insert if all message_ids are valid\n",
    "if all(-2147483648 <= message['message_id'] <= 2147483647 for message in messages):\n",
    "    session.execute(messages_table.insert().values(messages))\n",
    "    logging.info('Bulk inserted messages')\n",
    "else:\n",
    "    logging.error('Bulk insert aborted due to invalid message_id values.')\n",
    "\n",
    "# Bulk insert media if any entries exist\n",
    "if media_entries:\n",
    "    session.execute(media_table.insert().values(media_entries))\n",
    "    logging.info('Bulk inserted media')\n",
    "\n",
    "# Commit the session\n",
    "session.commit()\n",
    "logging.info(\"Data inserted successfully.\")\n",
    "\n",
    "# Close the session and connection\n",
    "session.close()\n",
    "logging.info(\"Session closed.\")\n",
    "\n",
    "print(\"Data inserted successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "Session Creation: The session is created using the engine from db.engine to manage transactions.\n",
    "\n",
    "\n",
    "Data Insertion: Data from scraped_data_cleaned.xlsx is inserted into the normalized tables. The session.execute() method is used for the insertion of records into channels, senders, messages, and media tables.\n",
    "\n",
    "\n",
    "Committing the Transaction: After all inserts, the session is committed to save the changes to the database.\n",
    "\n",
    "\n",
    "Session and Connection Closing: Both the session and database connection are closed to ensure proper resource management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Senders data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sender_id sender_name\n",
      "0 -1001102021238        None\n",
      "1 -1001432982009        None\n",
      "2 -1001447066276        None\n",
      "3 -1001666492664        None\n"
     ]
    }
   ],
   "source": [
    "# Define a query to fetch data from the xdr_data table\n",
    "query = \"SELECT * FROM senders;\"\n",
    "\n",
    "# Fetch data\n",
    "data = db.fetch_data(query)\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Check if data is returned\n",
    "if data is not None and not data.empty:\n",
    "    # Display the DataFrame\n",
    "    print(data.head())\n",
    "else:\n",
    "    print(\"No data available or data is empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### messages data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   message_id                                            message  \\\n",
      "0         864  https://youtu.be/5DBoEm-8kmA?si=LDLuEecNfULJVD...   \n",
      "1         863  á‹¶áŠ­á‰°áˆ­áˆµ áŠ¢á‰µá‹®áŒµá‹« á‰  áŠ á‹²áˆµ ...   \n",
      "2         862  áˆžá‰µ á‰ áˆµáŠ³áˆ­ \\n\\náˆˆáˆáŒ†á‰»á‰½áŠ• á‹¨...   \n",
      "3         861  áŠ¨ HIV á‹¨á‰°áˆá‹ˆáˆ° áˆ°á‹ áŠ áŒ‹áŒ¥áˆŸá‰½...   \n",
      "4         860  á‰ á‰…áˆ­á‰¥ áŒŠá‹œ á‰ áˆƒáŒˆáˆ«á‰½áŠ• áˆ‹á‹­ ...   \n",
      "\n",
      "                 date      sender_id  channel_id  \n",
      "0 2023-12-18 17:04:02 -1001102021238           1  \n",
      "1 2023-11-03 16:14:39 -1001102021238           1  \n",
      "2 2023-10-02 16:37:39 -1001102021238           1  \n",
      "3 2023-09-16 07:54:32 -1001102021238           1  \n",
      "4 2023-09-01 16:16:15 -1001102021238           1  \n"
     ]
    }
   ],
   "source": [
    "# Define a query to fetch data from the xdr_data table\n",
    "query = \"SELECT * FROM messages;\"\n",
    "\n",
    "# Fetch data\n",
    "data = db.fetch_data(query)\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Check if data is returned\n",
    "if data is not None and not data.empty:\n",
    "    # Display the DataFrame\n",
    "    print(data.head())\n",
    "else:\n",
    "    print(\"No data available or data is empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### media data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   media_id media_path  message_id\n",
      "0         1   No Media         864\n",
      "1         2   No Media         863\n",
      "2         3   No Media         862\n",
      "3         4   No Media         861\n",
      "4         5   No Media         860\n"
     ]
    }
   ],
   "source": [
    "# Define a query to fetch data from the xdr_data table\n",
    "query = \"SELECT * FROM media;\"\n",
    "\n",
    "# Fetch data\n",
    "data = db.fetch_data(query)\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Check if data is returned\n",
    "if data is not None and not data.empty:\n",
    "    # Display the DataFrame\n",
    "    print(data.head())\n",
    "else:\n",
    "    print(\"No data available or data is empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### channels data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   channel_id       channel_name\n",
      "0           1          DoctorsET\n",
      "1           2              EAHCI\n",
      "2           3          yetenaweg\n",
      "3           4  lobelia4cosmetics\n"
     ]
    }
   ],
   "source": [
    "# Define a query to fetch data from the xdr_data table\n",
    "query = \"SELECT * FROM channels;\"\n",
    "\n",
    "# Fetch data\n",
    "data = db.fetch_data(query)\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Check if data is returned\n",
    "if data is not None and not data.empty:\n",
    "    # Display the DataFrame\n",
    "    print(data.head())\n",
    "else:\n",
    "    print(\"No data available or data is empty.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
